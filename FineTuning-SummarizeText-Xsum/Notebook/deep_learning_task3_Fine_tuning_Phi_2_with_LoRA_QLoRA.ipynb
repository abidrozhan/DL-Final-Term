{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NOTEBOOK 3: FINE-TUNING PHI-2 WITH LORA**\n",
        "\n",
        "\n",
        "Task 3: Fine-tuning Phi-2 for Text Summarization with XSum\n",
        "UAS Deep Learning - Final Term Assignment\n",
        "\n",
        "This notebook:\n",
        "1. Loads formatted data from Google Drive\n",
        "2. Configures Phi-2 model with LoRA for efficient fine-tuning\n",
        "3. Sets up training with optimal hyperparameters\n",
        "4. Trains the model with monitoring\n",
        "5. Saves the fine-tuned model"
      ],
      "metadata": {
        "id": "nrOr960hI86z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SETUP & INSTALLATIONS**"
      ],
      "metadata": {
        "id": "rbuHKJP09uxn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpf4jNq19nbZ",
        "outputId": "a7086aab-1751-46ee-de6c-b3c5b7914d64"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "NOTEBOOK 3: FINE-TUNING PHI-2 WITH LORA\n",
            "======================================================================\n",
            "\n",
            "Installing libraries (this may take a few minutes)...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"NOTEBOOK 3: FINE-TUNING PHI-2 WITH LORA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Install required libraries\n",
        "print(\"\\nInstalling libraries (this may take a few minutes)...\")\n",
        "!pip install 'datasets==3.1.0' -q\n",
        "!pip install transformers accelerate -q\n",
        "!pip install peft -q  # For LoRA\n",
        "!pip install bitsandbytes -q  # For 4-bit quantization (QLoRA)\n",
        "!pip install trl -q  # For SFTTrainer\n",
        "\n",
        "print(\"‚úì Installation complete!\")\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "import json\n",
        "from datasets import load_from_disk\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "\n",
        "print(\"‚úì Libraries imported successfully!\")\n",
        "\n",
        "# Check GPU\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GPU CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  WARNING: No GPU detected! Training will be very slow.\")\n",
        "    print(\"   Go to Runtime > Change runtime type > Select GPU (T4)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD PREPROCESSED DATA FROM DRIVE**"
      ],
      "metadata": {
        "id": "Vgr38eTH-AEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LOADING DATA FROM GOOGLE DRIVE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "PROJECT_DIR = '/content/drive/MyDrive/DL_FinalTask_XSum'\n",
        "\n",
        "print(f\"‚úì Mounted Drive at: {PROJECT_DIR}\")\n",
        "\n",
        "# Load formatting config\n",
        "with open(f'{PROJECT_DIR}/formatting_config.json', 'r') as f:\n",
        "    formatting_config = json.load(f)\n",
        "\n",
        "print(\"\\n‚úì Loaded formatting configuration\")\n",
        "\n",
        "# Choose dataset size\n",
        "# For initial experiments: use small dataset (faster)\n",
        "# For final training: use full dataset\n",
        "USE_SMALL_DATASET = True  # Change to False for full training\n",
        "\n",
        "if USE_SMALL_DATASET:\n",
        "    print(\"\\nüìä Loading SMALL dataset (for fast experimentation)...\")\n",
        "    tokenized_datasets = load_from_disk(f'{PROJECT_DIR}/xsum_tokenized_small')\n",
        "else:\n",
        "    print(\"\\nüìä Loading FULL dataset (for final training)...\")\n",
        "    tokenized_datasets = load_from_disk(f'{PROJECT_DIR}/xsum_tokenized_full')\n",
        "\n",
        "# Remove the 'labels' column to let DataCollatorForLanguageModeling generate them\n",
        "# This is a common fix for ValueError when pre-existing labels conflict with collator's padding logic\n",
        "if 'labels' in tokenized_datasets['train'].features:\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns(['labels'])\n",
        "    print(\"‚úì Removed 'labels' column from dataset to ensure proper collator behavior.\")\n",
        "\n",
        "print(f\"‚úì Dataset loaded!\")\n",
        "print(f\"   Training samples: {len(tokenized_datasets['train']):,}\")\n",
        "print(f\"   Validation samples: {len(tokenized_datasets['validation']):,}\")"
      ],
      "metadata": {
        "id": "jI-GZf3u-Dte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD PHI-2 MODEL WITH QUANTIZATION**"
      ],
      "metadata": {
        "id": "cIh2JpDv-WyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LOADING PHI-2 MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load tokenizer\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"microsoft/phi-2\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "print(\"‚úì Tokenizer loaded\")\n",
        "\n",
        "# Configure 4-bit quantization for memory efficiency (QLoRA)\n",
        "print(\"\\nConfiguring 4-bit quantization (QLoRA)...\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "print(\"‚úì Quantization config created\")\n",
        "\n",
        "# Load model with quantization\n",
        "print(\"\\nLoading Phi-2 model (this may take 2-3 minutes)...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/phi-2\",\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "print(\"‚úì Model loaded successfully!\")\n",
        "print(f\"   Model device: {model.device}\")\n",
        "print(f\"   Model dtype: {model.dtype}\")\n",
        "\n",
        "# Get model size\n",
        "param_count = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"   Total parameters: {param_count:,}\")\n",
        "print(f\"   Trainable parameters: {trainable_params:,}\")"
      ],
      "metadata": {
        "id": "dcStrBM1-bU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONFIGURE LORA**"
      ],
      "metadata": {
        "id": "uNSuRpc4-loX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONFIGURING LORA (LOW-RANK ADAPTATION)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Prepare model for k-bit training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "print(\"‚úì Model prepared for k-bit training\")\n",
        "\n",
        "# LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,  # Rank - higher = more parameters but better learning\n",
        "    lora_alpha=32,  # Scaling factor\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"dense\",\n",
        "        \"fc1\",\n",
        "        \"fc2\"\n",
        "    ],  # Which layers to apply LoRA\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "print(\"LoRA Configuration:\")\n",
        "print(f\"   Rank (r): {lora_config.r}\")\n",
        "print(f\"   Alpha: {lora_config.lora_alpha}\")\n",
        "print(f\"   Dropout: {lora_config.lora_dropout}\")\n",
        "print(f\"   Target modules: {lora_config.target_modules}\")\n",
        "\n",
        "# Apply LoRA to model\n",
        "model = get_peft_model(model, lora_config)\n",
        "print(\"\\n‚úì LoRA applied to model!\")\n",
        "\n",
        "# Print trainable parameters\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "all_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_percent = 100 * trainable_params / all_params\n",
        "\n",
        "print(f\"\\nüìä Training Statistics:\")\n",
        "print(f\"   Total parameters: {all_params:,}\")\n",
        "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"   Trainable %: {trainable_percent:.4f}%\")\n",
        "print(f\"   Memory savings: ~{100 - trainable_percent:.2f}% reduction in training params!\")"
      ],
      "metadata": {
        "id": "a4wjPVYj-m3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FIX DATASET FORMAT**"
      ],
      "metadata": {
        "id": "uboNXbsIQUg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FIXING DATASET FORMAT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def fix_labels(example):\n",
        "    \"\"\"Ensure labels are properly formatted as a list\"\"\"\n",
        "    # If labels don't exist or are None, copy from input_ids\n",
        "    if 'labels' not in example or example['labels'] is None:\n",
        "        example['labels'] = example['input_ids'][:]\n",
        "\n",
        "    # Ensure both are lists of ints\n",
        "    if not isinstance(example['input_ids'], list):\n",
        "        example['input_ids'] = list(example['input_ids'])\n",
        "    if not isinstance(example['labels'], list):\n",
        "        example['labels'] = list(example['labels'])\n",
        "\n",
        "    # Ensure they're the same length\n",
        "    if len(example['input_ids']) != len(example['labels']):\n",
        "        example['labels'] = example['input_ids'][:]\n",
        "\n",
        "    return example\n",
        "\n",
        "print(\"Applying format fixes to dataset...\")\n",
        "tokenized_datasets = tokenized_datasets.map(\n",
        "    fix_labels,\n",
        "    desc=\"Fixing labels\"\n",
        ")\n",
        "\n",
        "# Remove any columns that might cause issues\n",
        "columns_to_keep = ['input_ids', 'attention_mask', 'labels']\n",
        "columns_to_remove = [col for col in tokenized_datasets['train'].column_names\n",
        "                     if col not in columns_to_keep]\n",
        "\n",
        "if columns_to_remove:\n",
        "    print(f\"Removing extra columns: {columns_to_remove}\")\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns(columns_to_remove)\n",
        "\n",
        "print(f\"‚úì Dataset fixed!\")\n",
        "print(f\"   Columns: {tokenized_datasets['train'].column_names}\")\n",
        "\n",
        "# Verify fix worked\n",
        "sample = tokenized_datasets['train'][0]\n",
        "print(f\"\\n‚úì Verification:\")\n",
        "print(f\"   input_ids: list of {len(sample['input_ids'])} ints\")\n",
        "print(f\"   labels: list of {len(sample['labels'])} ints\")\n",
        "print(f\"   Match: {len(sample['input_ids']) == len(sample['labels'])}\")"
      ],
      "metadata": {
        "id": "BzVADeioQRyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SETUP DATA COLLATOR**"
      ],
      "metadata": {
        "id": "r2jbzOUbNXuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SETTING UP DATA COLLATOR\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# Use DataCollatorForSeq2Seq which handles padding better\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=-100,\n",
        "    padding=True\n",
        ")\n",
        "\n",
        "print(\"‚úì Data collator configured\")\n",
        "print(\"   Type: Seq2Seq with dynamic padding\")\n",
        "print(\"   Label padding: -100 (ignored in loss)\")"
      ],
      "metadata": {
        "id": "55zVwtUQNZBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONFIGURE TRAINING ARGUMENTS**"
      ],
      "metadata": {
        "id": "cP7BqJcGNa8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONFIGURING TRAINING HYPERPARAMETERS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "OUTPUT_DIR = \"/content/phi2-xsum-lora\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=2e-4,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_steps=100,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    weight_decay=0.01,\n",
        "    max_grad_norm=1.0,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    logging_steps=25,\n",
        "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
        "    report_to=\"none\",\n",
        "    fp16=True,\n",
        "    dataloader_num_workers=0,  # IMPORTANT: Set to 0 to avoid multiprocessing issues\n",
        "    remove_unused_columns=False,  # Keep all columns for now\n",
        "    push_to_hub=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(\"‚úì Training configured\")"
      ],
      "metadata": {
        "id": "-o1y6Jv7NdW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INITIALIZE TRAINER**"
      ],
      "metadata": {
        "id": "My-Brug2NhaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INITIALIZING TRAINER\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"‚úì Trainer initialized!\")\n",
        "\n",
        "# CRITICAL: Test that batching works before training\n",
        "print(\"\\nüîç Testing data loading...\")\n",
        "try:\n",
        "    test_dataloader = trainer.get_train_dataloader()\n",
        "    test_batch = next(iter(test_dataloader))\n",
        "    print(f\"‚úì Data loading successful!\")\n",
        "    print(f\"   Batch size: {test_batch['input_ids'].shape}\")\n",
        "    print(f\"   Labels shape: {test_batch['labels'].shape}\")\n",
        "    del test_dataloader, test_batch\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Data loading failed: {e}\")\n",
        "    print(\"\\nDebugging info:\")\n",
        "    sample = tokenized_datasets['train'][0]\n",
        "    for key in sample.keys():\n",
        "        print(f\"   {key}: {type(sample[key])}, length: {len(sample[key]) if hasattr(sample[key], '__len__') else 'N/A'}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "1OcC5PmXNjpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 7B: ENHANCED PROGRESS TRACKING WITH LIVE PLOTTING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SETTING UP ENHANCED PROGRESS TRACKING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from transformers import TrainerCallback\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class EnhancedProgressCallback(TrainerCallback):\n",
        "    \"\"\"Callback with progress bar, ETA, and live loss plotting\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.training_bar = None\n",
        "        self.start_time = None\n",
        "        self.losses = []\n",
        "        self.steps = []\n",
        "        self.eval_losses = []\n",
        "        self.eval_steps = []\n",
        "\n",
        "    def on_train_begin(self, args, state, control, **kwargs):\n",
        "        self.start_time = time.time()\n",
        "        total_steps = state.max_steps\n",
        "        print(f\"\\nüöÄ Training Started!\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"üìä Configuration:\")\n",
        "        print(f\"   Total steps: {total_steps}\")\n",
        "        print(f\"   Total epochs: {args.num_train_epochs}\")\n",
        "        print(f\"   Train samples: {len(trainer.train_dataset):,}\")\n",
        "        print(f\"   Batch size: {args.per_device_train_batch_size}\")\n",
        "        print(f\"   Gradient accumulation: {args.gradient_accumulation_steps}\")\n",
        "        print(f\"   Effective batch size: {args.per_device_train_batch_size * args.gradient_accumulation_steps}\")\n",
        "        print(f\"   Learning rate: {args.learning_rate}\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        self.training_bar = tqdm(\n",
        "            total=total_steps,\n",
        "            desc=\"üî• Training\",\n",
        "            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'\n",
        "        )\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        \"\"\"Called when logging happens\"\"\"\n",
        "        if logs:\n",
        "            if 'loss' in logs:\n",
        "                self.losses.append(logs['loss'])\n",
        "                self.steps.append(state.global_step)\n",
        "            if 'eval_loss' in logs:\n",
        "                self.eval_losses.append(logs['eval_loss'])\n",
        "                self.eval_steps.append(state.global_step)\n",
        "\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        if self.training_bar:\n",
        "            self.training_bar.update(1)\n",
        "\n",
        "            # Calculate time estimates\n",
        "            elapsed = time.time() - self.start_time\n",
        "            steps_done = state.global_step\n",
        "            steps_remaining = state.max_steps - steps_done\n",
        "\n",
        "            if steps_done > 0:\n",
        "                time_per_step = elapsed / steps_done\n",
        "                eta_seconds = time_per_step * steps_remaining\n",
        "\n",
        "                # Format times\n",
        "                elapsed_str = self._format_time(elapsed)\n",
        "                eta_str = self._format_time(eta_seconds)\n",
        "\n",
        "                # Get current metrics\n",
        "                current_loss = self.losses[-1] if self.losses else 0\n",
        "                current_lr = state.log_history[-1].get('learning_rate', 0) if state.log_history else 0\n",
        "\n",
        "                # Update progress bar\n",
        "                self.training_bar.set_postfix({\n",
        "                    'loss': f'{current_loss:.4f}',\n",
        "                    'lr': f'{current_lr:.2e}',\n",
        "                    'elapsed': elapsed_str,\n",
        "                    'ETA': eta_str\n",
        "                })\n",
        "\n",
        "    def on_evaluate(self, args, state, control, **kwargs):\n",
        "        \"\"\"Show quick evaluation update\"\"\"\n",
        "        if self.eval_losses:\n",
        "            print(f\"\\nüìä Evaluation at step {state.global_step}: loss = {self.eval_losses[-1]:.4f}\")\n",
        "\n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        if self.training_bar:\n",
        "            self.training_bar.close()\n",
        "\n",
        "        total_time = time.time() - self.start_time\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"‚úÖ TRAINING COMPLETED!\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"‚è±Ô∏è  Total time: {self._format_time(total_time)}\")\n",
        "        print(f\"üìâ Final train loss: {self.losses[-1]:.4f}\")\n",
        "        if self.eval_losses:\n",
        "            print(f\"üìâ Final eval loss: {self.eval_losses[-1]:.4f}\")\n",
        "        print(f\"‚ö° Average speed: {state.max_steps/total_time:.2f} steps/sec\")\n",
        "\n",
        "        # Plot training curve\n",
        "        self._plot_training_curve()\n",
        "\n",
        "    def _format_time(self, seconds):\n",
        "        \"\"\"Format seconds into human readable time\"\"\"\n",
        "        if seconds < 60:\n",
        "            return f\"{seconds:.0f}s\"\n",
        "        elif seconds < 3600:\n",
        "            return f\"{seconds/60:.1f}min\"\n",
        "        else:\n",
        "            hours = seconds / 3600\n",
        "            return f\"{hours:.1f}h\"\n",
        "\n",
        "    def _plot_training_curve(self):\n",
        "        \"\"\"Plot training and validation loss curves\"\"\"\n",
        "        if not self.losses:\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        # Training loss\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.steps, self.losses, label='Training Loss', color='blue', alpha=0.7)\n",
        "        if self.eval_losses:\n",
        "            plt.scatter(self.eval_steps, self.eval_losses,\n",
        "                       label='Validation Loss', color='red', s=50, zorder=5)\n",
        "        plt.xlabel('Steps')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Progress')\n",
        "        plt.legend()\n",
        "        plt.grid(alpha=0.3)\n",
        "\n",
        "        # Loss moving average\n",
        "        plt.subplot(1, 2, 2)\n",
        "        if len(self.losses) > 10:\n",
        "            window = min(50, len(self.losses) // 10)\n",
        "            smoothed = np.convolve(self.losses, np.ones(window)/window, mode='valid')\n",
        "            smoothed_steps = self.steps[window-1:]\n",
        "            plt.plot(smoothed_steps, smoothed, label='Smoothed Training Loss',\n",
        "                    color='blue', linewidth=2)\n",
        "        else:\n",
        "            plt.plot(self.steps, self.losses, label='Training Loss', color='blue')\n",
        "\n",
        "        if self.eval_losses:\n",
        "            plt.scatter(self.eval_steps, self.eval_losses,\n",
        "                       label='Validation Loss', color='red', s=50, zorder=5)\n",
        "        plt.xlabel('Steps')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Smoothed Training Progress')\n",
        "        plt.legend()\n",
        "        plt.grid(alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{OUTPUT_DIR}/training_curve.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"\\n‚úì Training curve saved to: {OUTPUT_DIR}/training_curve.png\")\n",
        "        plt.show()\n",
        "\n",
        "# Add callback\n",
        "progress_callback = EnhancedProgressCallback()\n",
        "trainer.add_callback(progress_callback)\n",
        "\n",
        "print(\"‚úì Enhanced progress tracking enabled!\")\n",
        "print(\"   Features:\")\n",
        "print(\"   ‚úì Real-time progress bar with ETA\")\n",
        "print(\"   ‚úì Current loss and learning rate display\")\n",
        "print(\"   ‚úì Elapsed time tracking\")\n",
        "print(\"   ‚úì Training curve visualization at end\")\n"
      ],
      "metadata": {
        "id": "JuTJolMrRitQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**START TRAINING**"
      ],
      "metadata": {
        "id": "Isq7U8kHNmPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üöÄ STARTING TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "training_result = trainer.train()\n",
        "\n",
        "print(\"\\n‚úÖ TRAINING COMPLETE!\")"
      ],
      "metadata": {
        "id": "7RSplyRkNo8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATE MODEL**"
      ],
      "metadata": {
        "id": "SZW2P5-xN-23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING TRAINED MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "print(\"\\nüìä Evaluation Results:\")\n",
        "print(f\"   Eval loss: {eval_results['eval_loss']:.4f}\")\n",
        "print(f\"   Eval runtime: {eval_results['eval_runtime']:.2f} seconds\")\n",
        "print(f\"   Eval samples/second: {eval_results['eval_samples_per_second']:.2f}\")\n",
        "print(f\"   Perplexity: {np.exp(eval_results['eval_loss']):.2f}\")"
      ],
      "metadata": {
        "id": "T0I6ry4WOBci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE MODEL TO DRIVE**"
      ],
      "metadata": {
        "id": "NuYZ4AHnODFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAVING FINE-TUNED MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save locally first\n",
        "model.save_pretrained(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "print(f\"‚úì Model saved locally to: {OUTPUT_DIR}\")\n",
        "\n",
        "# Copy to Google Drive\n",
        "DRIVE_MODEL_DIR = f\"{PROJECT_DIR}/phi2_finetuned_model\"\n",
        "print(f\"\\nCopying model to Google Drive: {DRIVE_MODEL_DIR}\")\n",
        "\n",
        "import shutil\n",
        "if os.path.exists(DRIVE_MODEL_DIR):\n",
        "    shutil.rmtree(DRIVE_MODEL_DIR)\n",
        "shutil.copytree(OUTPUT_DIR, DRIVE_MODEL_DIR)\n",
        "\n",
        "print(\"‚úì Model saved to Google Drive!\")\n",
        "\n",
        "# Save training metrics\n",
        "metrics = {\n",
        "    'training': {\n",
        "        'train_loss': training_result.metrics['train_loss'],\n",
        "        'train_runtime': training_result.metrics['train_runtime'],\n",
        "        'train_samples_per_second': training_result.metrics['train_samples_per_second'],\n",
        "    },\n",
        "    'evaluation': {\n",
        "        'eval_loss': eval_results['eval_loss'],\n",
        "        'perplexity': float(np.exp(eval_results['eval_loss'])),\n",
        "    },\n",
        "    'configuration': {\n",
        "        'num_epochs': training_args.num_train_epochs,\n",
        "        'batch_size': training_args.per_device_train_batch_size,\n",
        "        'learning_rate': training_args.learning_rate,\n",
        "        'lora_r': lora_config.r,\n",
        "        'lora_alpha': lora_config.lora_alpha,\n",
        "        'dataset_size': 'small' if USE_SMALL_DATASET else 'full',\n",
        "        'train_samples': len(tokenized_datasets['train']),\n",
        "        'val_samples': len(tokenized_datasets['validation'])\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(f'{DRIVE_MODEL_DIR}/training_metrics.json', 'w') as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "\n",
        "print(\"‚úì Training metrics saved!\")"
      ],
      "metadata": {
        "id": "Shr7xanqOF_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST GENERATION**"
      ],
      "metadata": {
        "id": "AGLkhSSfOIHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING MODEL GENERATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test on a few validation examples\n",
        "print(\"\\nGenerating summaries for sample articles...\\n\")\n",
        "\n",
        "# Get test examples\n",
        "test_examples = tokenized_datasets['validation'].select(range(3))\n",
        "\n",
        "for i, example in enumerate(test_examples):\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Example {i+1}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Decode the input (will include the prompt)\n",
        "    input_text = tokenizer.decode(example['input_ids'][:800], skip_special_tokens=True)\n",
        "\n",
        "    # Extract just the article part (before \"Summarize\")\n",
        "    if \"Summarize the above article\" in input_text:\n",
        "        article_part = input_text.split(\"Summarize the above article\")[0].replace(\"Article:\", \"\").strip()\n",
        "    else:\n",
        "        article_part = input_text[:300]\n",
        "\n",
        "    print(f\"\\nArticle (first 300 chars):\\n{article_part[:300]}...\")\n",
        "\n",
        "    # Ground truth\n",
        "    print(f\"\\nGround Truth Summary:\\n{example['target_summary']}\")\n",
        "\n",
        "    # Generate with the model\n",
        "    prompt = f\"Article: {article_part}\\n\\nSummarize the above article in one sentence.\\nSummary:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=50,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract just the summary part (after \"Summary:\")\n",
        "    if \"Summary:\" in generated_text:\n",
        "        generated_summary = generated_text.split(\"Summary:\")[-1].strip()\n",
        "    else:\n",
        "        generated_summary = generated_text\n",
        "\n",
        "    print(f\"\\nGenerated Summary:\\n{generated_summary}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"‚úÖ MODEL TESTING COMPLETE!\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "J9zgW7aIOKAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FINAL SUMMARY**"
      ],
      "metadata": {
        "id": "NDnrgE78OMNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéâ NOTEBOOK 3 COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n‚úÖ Achievements:\")\n",
        "print(\"   1. Loaded and prepared Phi-2 model with 4-bit quantization\")\n",
        "print(\"   2. Applied LoRA for efficient fine-tuning\")\n",
        "print(f\"   3. Trained for {training_args.num_train_epochs} epochs\")\n",
        "print(f\"   4. Achieved eval loss: {eval_results['eval_loss']:.4f}\")\n",
        "print(f\"   5. Saved fine-tuned model to Google Drive\")\n",
        "print(\"   6. Tested generation on sample articles\")\n",
        "\n",
        "print(f\"\\nüìÅ Model Location:\")\n",
        "print(f\"   {DRIVE_MODEL_DIR}\")\n",
        "\n",
        "print(\"\\nüöÄ Next Steps:\")\n",
        "print(\"   ‚Üí Proceed to Notebook 4: Comprehensive Evaluation & Analysis\")\n",
        "print(\"   ‚Üí Calculate ROUGE scores\")\n",
        "print(\"   ‚Üí Generate analysis visualizations\")\n",
        "print(\"   ‚Üí Create final report\")"
      ],
      "metadata": {
        "id": "c8ZkQ1LZON65"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}